import { createClient } from '@supabase/supabase-js';
import dotenv from 'dotenv';
import path from 'path';
import { fileURLToPath } from 'url';

// --- ConfiguraÃ§Ã£o IdÃªntica ---
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const projectRoot = path.resolve(__dirname, '..');
dotenv.config({ path: path.resolve(projectRoot, '.env') });

const supabaseUrl = process.env.VITE_SUPABASE_URL;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY;
const BUCKET_NAME = 'imagens';

if (!supabaseUrl || !supabaseServiceKey) {
  console.error('âŒ Erro: VariÃ¡veis de ambiente sÃ£o necessÃ¡rias.');
  process.exit(1);
}
const supabase = createClient(supabaseUrl, supabaseServiceKey);
// --- Fim da ConfiguraÃ§Ã£o ---

/**
 * Extrai o caminho do arquivo de uma URL do Supabase Storage.
 */
function getPathFromUrl(url) {
  try {
    const urlObject = new URL(url);
    const pathSegments = urlObject.pathname.split('/');
    const bucketIndex = pathSegments.indexOf(BUCKET_NAME);
    return bucketIndex === -1 ? null : pathSegments.slice(bucketIndex + 1).join('/');
  } catch {
    return null;
  }
}

/**
 * Verifica a existÃªncia de uma lista de arquivos no Storage.
 * @param filePaths - Array com os caminhos dos arquivos.
 * @returns Um Set com os caminhos dos arquivos que realmente existem.
 */
async function checkFilesExist(filePaths) {
  // O Supabase nÃ£o tem um mÃ©todo "exists" em lote, entÃ£o buscamos os metadados.
  // Isso Ã© mais eficiente do que fazer um loop de chamadas individuais.
  const { data: existingFilesData, error } = await supabase.storage.from(BUCKET_NAME).list(null, {
    limit: 10000, // Assumindo que o nÃºmero de arquivos totais Ã© menor que o limite
  });

  if (error) {
    console.error('Erro ao listar arquivos do Storage para verificaÃ§Ã£o:', error);
    return new Set();
  }

  const existingFileNames = new Set(existingFilesData.map(f => f.name));
  const verifiedPaths = filePaths.filter(path => existingFileNames.has(path));

  return new Set(verifiedPaths);
}

/**
 * LÃ³gica principal do script de sincronizaÃ§Ã£o.
 */
async function runSync() {
  console.log('Iniciando sincronizaÃ§Ã£o do Banco de Dados com o Storage...');

  try {
    const { data: trabalhos, error: fetchError } = await supabase
      .from('portfolio_trabalhos')
      .select('id, titulo, imagens, imagem_capa');

    if (fetchError) throw fetchError;

    const correctionsToApply = [];
    const allFilePathsToCheck = new Set();

    // 1. Coletar todos os caminhos de arquivo para uma Ãºnica verificaÃ§Ã£o em lote
    trabalhos.forEach(trabalho => {
      trabalho.imagens?.forEach(url => {
        const path = getPathFromUrl(url);
        if (path) allFilePathsToCheck.add(path);
      });
    });

    const existingFilePaths = await checkFilesExist(Array.from(allFilePathsToCheck));

    // 2. Determinar quais correÃ§Ãµes sÃ£o necessÃ¡rias
    for (const trabalho of trabalhos) {
      if (!trabalho.imagens || trabalho.imagens.length === 0) continue;

      const originalImageCount = trabalho.imagens.length;
      const validImageUrls = [];
      const invalidImageUrls = [];

      trabalho.imagens.forEach(url => {
        const path = getPathFromUrl(url);
        if (path && existingFilePaths.has(path)) {
          validImageUrls.push(url);
        } else {
          invalidImageUrls.push(url);
        }
      });
      
      if (invalidImageUrls.length > 0) {
        let newCoverImage = trabalho.imagem_capa;
        // Se a imagem de capa era uma das invÃ¡lidas, define uma nova
        if (invalidImageUrls.includes(trabalho.imagem_capa)) {
          newCoverImage = validImageUrls.length > 0 ? validImageUrls[0] : null;
        }

        correctionsToApply.push({
          id: trabalho.id,
          titulo: trabalho.titulo,
          invalidUrls: invalidImageUrls,
          newImageArray: validImageUrls,
          newCoverImage: newCoverImage,
          needsUpdate: originalImageCount !== validImageUrls.length || newCoverImage !== trabalho.imagem_capa
        });
      }
    }

    // 3. Exibir o relatÃ³rio
    if (correctionsToApply.length === 0) {
      console.log('âœ… Banco de Dados estÃ¡ consistente com o Storage. Nenhuma aÃ§Ã£o necessÃ¡ria.');
      return;
    }

    console.log(`\nğŸ”´ Encontrados ${correctionsToApply.length} trabalhos com ${correctionsToApply.reduce((acc, c) => acc + c.invalidUrls.length, 0)} imagens quebradas.`);
    correctionsToApply.forEach(corr => {
      console.log(`\n  - Trabalho: "${corr.titulo}" (ID: ${corr.id})`);
      corr.invalidUrls.forEach(url => console.log(`    - âŒ URL InvÃ¡lida: ${url}`));
    });

    // 4. Aplicar correÃ§Ãµes, se a flag for passada
    const shouldFix = process.argv.includes('--fix');
    if (shouldFix) {
      console.log('\n\nğŸ”¥ Aplicando correÃ§Ãµes... (Flag --fix detectada)');
      const updatePromises = correctionsToApply
        .filter(c => c.needsUpdate)
        .map(c => 
          supabase.from('portfolio_trabalhos').update({ 
            imagens: c.newImageArray,
            imagem_capa: c.newCoverImage,
            atualizado_em: new Date().toISOString()
          }).eq('id', c.id)
        );
      
      const results = await Promise.all(updatePromises);
      const errors = results.filter(r => r.error);

      if (errors.length > 0) {
        console.error('âŒ Ocorreram erros ao atualizar alguns registros:', errors);
      } else {
        console.log('âœ… Banco de Dados sincronizado com sucesso!');
      }

    } else {
      console.log('\n\nğŸ‘‰ Modo de "listagem apenas". Nenhuma alteraÃ§Ã£o foi feita no banco de dados.');
      console.log('ğŸ‘‰ Para aplicar essas correÃ§Ãµes, rode o script com a flag: node scripts/sync-db-with-storage.mjs --fix');
    }

  } catch (error) {
    console.error('\nâŒ O script de sincronizaÃ§Ã£o falhou:', error.message);
    process.exit(1);
  }
}

runSync(); 